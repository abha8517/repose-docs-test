[{"topic_url": "8.6.2.0/architecture/configuration.html", "title": "8.6.2.0 | Architecture | Configuration", "content": "\nAfter installing Repose, config files can be found in /etc/repose.\nAt a minimum, Repose needs a container.cfg.xml and system-model.cfg.xml to start.\n\nThe container.cfg.xml config file tells Repose where to find component artifacts and where to deploy them while running.\nSee Container for more details.\n\nThe main config file is system-model.cfg.xml.\nThis file configures the list of filters, the deployment layout, and the location of the origin service.\nOut of the box, Repose is setup to run as a single node listening on port 8080, to run with no filters and services enabled, and to point to rackspace.com on port 80 as the origin service.\nSee System Model for more details.\n\nMost filters and services have their own configuration file.\nSee Filters and Services for more details.\n\nRepose reads the config files when it starts up and when a file gets updated.\nThe configuration files are checked for updates every 15 seconds.\nThis is not configurable nor can it be manually triggered.\n\nWhen the config files are invalid, Repose will continue using the previous known good configuration, or if Repose was just initially starting up, then it will return a 503 until the config files are fixed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/architecture/container.html", "title": "8.6.2.0 | Architecture | Container", "content": "\nThe container configuration is required to set up Repose.\nIt is used to tell the system where to look for component artifacts and where to deploy them.\n\nThe following example shows a basic configuration for the Container file.\n\nA user may configure different values for different Repose clusters.\nThis is achieved by including one or more cluster-config elements which map to clusters in the system-model.\nAll configuration within a cluster-config element is optional.\nWhen configuration is present, it will override the base configuration (i.e., the deployment-config element) values.\nThis functionality may be referred to as \"container configuration patching\" or simply as \"patching\".\n\nWhen discussing patches, one might notice that there is ambiguity in the rules for how patches are applied.\nBelow is a list of common ambiguities, and how they are handled in this context:\n\nNot all configuration is patchable.\nSome values (e.g., the deployment-directory) cannot be overridden due to internal system constraints.\nCurrently the only items that are patchable are some of the deployment-config element\u2019s attributes.\nSpecifically only the following:\n\nSomething else to be aware of is that the deployment-directory and artifact-directory values should be fully qualified paths.\nThis is the case as the exact location of the launcing JVM may not remain in the same location and this would effect relative paths.\nThe path should not start or end with a whitespace character as all leading and trailing whitespace is ignored in reading this value.\nAll white space in the middle of the path name will be preserved and should not be escaped in any way.\n\nThe following assume:\n\nThe interaction between the deprecated via attribute and the new via-header element are as follows:\n\nThe following further assumes the deprecated via attribute is not defined and the via-header element contains:\n\nThere are two steps to supply a logging configuration for Repose:\n\nIf a user-supplied logging configuration file is not found, Repose programmatically sets default log4j properties.\nThis default properties add a\nConsoleAppender\nto the ROOT logger.\nThe output will be formatted using a\nPatternLayout\nset to the pattern %d %-4r [%t] %-5p %c - %m%n.\nThe default log level is set to DEBUG.\n\nSSL/TLS Client Authentication is being used more and more for communications between different enclaves.\nThis addition to the SSL/TLS handshake involves the Client presenting credentials to the Server in the same manner as the Server does to the Client.\nIf the credentials presented by the Client are not trusted, then the Server will sever the connection just as the Client would have if the situation was reversed.\nSince a Client initiates contact with the Server, the Server\u2019s credentials are simply to validate it is who the Client was trying to contact.\nThis is accomplished through Certificate Authorities (CA) and the Trust Hierarchies built into the Public Key Infrastructure (PKI).\nEven though you can optionally add a particular Server\u2019s credentials directly into a Client so that it will implicitly trust a particular Server essentially bypassing the distributed trust mechanism in favor of a more direct one, this is the only way to build a relationship for a Client to a Server.\n\nTo require SSL/TLS Client Authentication, set the need-client-auth attribute to True.\nWith this setting enabled, only Clients that have a Public Key imported into the trust store referenced by the truststore-filename element will be allowed to connect.\nThe truststore is a\nJava Keystore\nthat can be created/updated using the command line tool named aptly enough,\nkeytool.\nBelow is an example of importing a Client certificate (client.crt) into a truststore (truststore.jks):\n\nThis will update the keystore if it exists or create a new one if it doesn\u2019t.\nThe tool will also prompt for a password.\nThe password will be used to access an existing file or set as the password on a new one.\n\nTo use the truststore created/updated in the example above, the following would need to be added/updated in the container.cfg.xml file:\n\nFor more details, see:\n\nRepose Valve is based on Jetty and uses its services for SSL/TLS.\n\nTo make the Repose Proxy Server deployment option work with origin SSL/TLS requests:\n\nKeystore information is located within the <ssl-configuration> element as shown in the following example.\n\nSince security is a constantly moving target, any recommended configuration would quickly become out of date.\nA risk assessment should always be performed by the appropriately qualified people for your organization.\nLinks to industry-standard references are provided in the SSL References section below.\n\nRepose supports whitelisting and blacklisting specific protocols and ciphers by exposing portions of the Jetty\u2019s configuration via the container.cfg.xml file.\nYou can use this feature if a specific protocol or cipher has been compromised and you want to block its usage and secure Repose.\n\nIn the following example, the container configuration includes TLS v1.2 and TLS ciphers and excludes SSLv3 and SSL protocols.\n\nYou need to specify your keystore in the container configuration just as you would in Jetty.\n\nCertain attacks (such as Logjam) leverage the weakness of \"small\" Diffie-Hellman (DH) keys.\nTo mitigate the risk of such attackers, users may either exclude vulnerable ciphers, or lengthen the DH keys used by Repose.\nInstructions for the former are above.\nFor the latter, note the following:\n\nDiffie-Hellman (DH) keys of sizes less than 1024 bits have been deprecated because of their insufficient strength.\nIn JDK 8, you can customize the ephemeral DH key size with the system property jdk.tls.ephemeralDHKeySize.\n\nIn other words, the Java option -Djdk.tls.ephemeralDHKeySize=2048 can be passed when starting Repose to force the use of longer DH keys.\n\nFor more details, see Customizing DH Keys.\n\nFor more information about cipher suites and which ones to dis/allow when setting up Repose, see the following references:\n\nThe list of available ciphers and protocols varies depending on the JVM.\nWe have added a command line option to Repose Valve to display the available and default enabled ciphers and protocols:\n\nThis will dump a list of the default enabled SSL/TLS parameters for the JVM you\u2019re using.\nAdditionally, it will list all available ciphers and protocols, should you wish to use one of those.\n\nThis mode should only be used during development testing.\nThese settings are NOT intended for a production environment.\n\nWhen running in insecure mode, Repose will accept all certificates from external services with which it communicates (e.g. authentication service, origin service).\n\nWhen running the Valve deployment, Repose may be placed in insecure mode by passing in the -k option as follows:\n\nWhen running the ROOT.war deployment, Repose may be placed in insecure mode by passing in the following system property:\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/architecture/packages.html", "title": "8.6.2.0 | Architecture | Packages", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\nProvides details about the packages Repose maintains for easy installation by our users.\n\nThis section outlines where Repose files live in the filesystem after being extracted from one of our packages.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/architecture/performance.html", "title": "8.6.2.0 | Architecture | Performance", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\nPerformance testing is a method of testing various aspects of Repose in order to collect performance data.\nPerformance data can be used to determine the overhead of the aspects in question, both at a system resource level as well as at a response time level.\n\nTo performance test Repose, and collect the resulting data for analysis, the Framework is used.\n\nIn an attempt to provide the most meaningful data possible, the following test cases will be covered by independent tests:\n\nThe overall design of the automatic performance testing framework can be outlined succinctly by the following diagram:\n\nA code change in the Repose GitHub repository on the master branch will trigger a Jenkins job to run.\nThe Jenkins job will run the Ansible playbooks for all defined test cases.\nThe Ansible playbooks, in turn, will provision the necessary cloud resources and begin executing the Gatling simulations for each test case.\nAs Gatling runs, it will pipe the performance data it captures to InfluxDB.\nOnce Gatling execution completes, the cloud resources will be cleaned up, and the Ansible playbook will finish executing.\nGrafana will query InfluxDB to retrieve the performance data which is available in the Performance Tests dashboard.\n\nData will be transported from Gatling to InfluxDB using the Graphite line protocol.\nThe data being transferred will include numerous statistics calculated for a distinct time.\nTo get a better idea of the data in question, a sample has been provided which captures the number of request/response pairs sent at time 1492629621 as well as various statistics calculated from the amount of time taken to service those requests.\nNote that the sample data only captures a single second of the Gatling simulation.\nMuch more data of the same form would be expected for every second that the Gatling simulation ran.\n\nSystem data will be transported from Repose hosts to InfluxDB using Telegraf.\nMore specifically, Telegraf will collect system metrics like CPU usage, memory usage, and disk usage, and report those metrics to a UDP listener in InfluxDB.\nThese metrics will provide better insight into the system constraints of hosts running Repose.\n\nInfluxDB will process the data it receives through its Graphite listener port by applying configured templates.\nThese templates will translate the metric names from the Graphite line protocol into measurements, fields, tags, and values in the database.\n\nFor example, given the sample data provided in the Gatling section, the following template could be applied:\n\nResulting in a database full of entries like the following:\n\nTo learn more about how InfluxDB handles Graphite input, see Graphite Input.\n\nThe following diagram illustrates the interactions between each component referenced in the Design.\n\nIn the directory structure of the performance tests, all test-specific files are organized by test and category.\nThat is, each file is located in a directory named after the specific test which is itself located in a directory named after the category of test.\nFor example, the repose-aggregator/tests/performance-tests/roles/repose/files/config/ directory contains the filters/ and use-cases/ sub-directories and the common file log4j2.xml.\n\nAnsible supports Jinja2 templates.\nThese templates allow users to add dynamic content to files and Ansible variables.\nJinja2 templated files should always be placed in the templates/ sub-directory of a role directory and have a .j2 file extension.\n\nA Jenkins job is triggered any time that code on the master branch of the Repose Git Repository changes.\nThe Jenkins job will run the performance tests and publish the results automatically.\nDesign describes the full automated process in more detail.\n\nIf you have the appropriate permissions on the Repose Jenkins instance, you can run the performance-test Jenkins job to manually start a single performance test.\n\nWe use Puppet to manage our performance test environment.\nThe details of our environment can be found in our Puppet manifest.\nIf you have Puppet installed, you can download our manifest and re-create our environment by running puppet apply directly on the downloaded file.\n\nGrafana serves as the user interface to performance test data which can be seen in the Performance Tests dashboard.\n\nAfter test execution has completed, Gatling will generate an HTML report.\nThe report can be found inside an archive residing in the home directory with a file name like SamlFilterSimulationRepose-1496319945650.tar.gz.\nThe exact file name will be included in the output of the Fetch the Gatling results task which will resemble the following snippet:\n\nAfter the report archive is located, the contents must be extracted before the report can be viewed.\nThat can be done with a command like the following:\ntar xvf /home/perftester/SamlFilterSimulationRepose-1496319945650.tar.gz\n\nOnce the report has been extracted, it can be viewed by opening the index.html file with a web browser.\n\nIf you need to manually run Gatling, you can do so from the Gatling host.\n\nFiles and directories of interest:\n\nRun the simple use-case test for 15 minutes with a 5 minute warmup (20 minutes total):\n\nBy default, both the Repose test and the origin service test (i.e., Repose is bypassed) are run.\nYou can use Ansible tags to specify that only one of those tests should be run.\n\nYou can specify which cloud server flavor to use in the configuration overrides.\n\nBy default, the Repose start task will wait 5 minutes for Repose to start up.\nIf you expect Repose to take longer to start (e.g., due to a large WADL), you can increase this timeout using a command like the following:\n\nTo get Repose to use Saxon, add a saxon-license.lic file to the repose-aggregator/tests/performance-tests/roles/repose/files/ directory and pass in the following configuration override:\n\nYou can set the JVM Options (JAVA_OPTS) used by Repose by setting the following configuration override:\n\nUse the master playbook to run a performance test and immediately clean up afterwards without having to running the individual playbooks.\n\nYou can re-run a test using the same cloud resources by simply running the start_test.yml playbook again.\nYou can even specify different configuration overrides in subsequent runs, although there are some limitations.\nFor example, you can enable Saxon for a subsequent run, but you can\u2019t disable it afterwards.\nAlso, if you don\u2019t want the Repose JVM already warmed up from the previous run, you should have Ansible restart the Repose service.\nThis feature is considered experimental.\n\nYou can specify the base name of the directory containing the Gatling results in the configuration overrides.\nFor example, if you wanted the base name custom-base-name (resulting in a directory name resembling custom-base-name-repose-1487812914968), you would run:\n\nRunning a performance test with a unique naming prefix enables you to run a particular test multiple times simultaneously (each run requires a unique prefix):\n\nIf you\u2019re using the stop_test.yml playbook to clean up your cloud resources, you\u2019ll need to include the unique prefix to ensure the correct resources are deleted.\nIf the prefix is not specified, the wrong cloud resources or no cloud resources could end up being deleted, and in both cases, no error will be returned (due to idempotency).\n\nWhen running a Scripting filter test, the perf_test variable will look slightly different than it does for other tests.\nThe reason is that the scripting language to be used in the test is nested one level down in the perf_test variable value.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/architecture/system-model.html", "title": "8.6.2.0 | Architecture | System Model", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\nThe Repose system-model.cfg.xml is the main configuration file for Repose.\nIt outlines the entire deployment layout for the service cluster.\nRepose must be aware of this in order to configure itself and correctly coordinate routing if necessary.\nAdditionally, the system model lets Repose know where the other Repose nodes reside.\nUsing this information, Repose can coordinate its own clustering to help load balance or share data among nodes that share common filters.\n\nThis section is only meant to explain certain quirks of the system model, and to provide a link to the comprehensive configuration schema.\nOther aspects of configuration will be explained through examples. See: Repose Deployment Scenarios\n\nSince port numbers below 1024 are privileged, Repose typically can not connect directly to them.\nThere are several ways to go about getting around this, but one of the most generally accepted ways is to execute the following commands with root privilege (e.g. sudo):\n\nIN PROGRESS\n\nIN PROGRESS\n\nIN PROGRESS\n\nIN PROGRESS\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/add-header.html", "title": "8.6.2.0 | Filters | Add Header Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\nThe Add Header filter adds configured headers to a request and/or response.\nYou can use the filter to add new headers with specific values to a request chain, and it can also replace (i.e. remove any existing headers with the configured name) headers.\n\nThis filter does not require any request headers.\n\nThis filter has no dependencies on other filters and can be placed wherever it is needed in the filter chain.\n\nChanges to request headers vary based on configuration.\n\nThis filter does not modify the request body.\n\nThis filter is not strictly required by any other filters.\n\nThis filter does not modify the response body.\n\nChanges to response headers vary based on configuration.\n\nThis filter does not modify the response code.\n\nThis configuration will add a foo header to the request with a value of bar and a quality of 0.5.\nAny existing headers with the same name will not be removed.\n\nThis configuration will add a foo header to the response with a value of bar and a quality of 0.5.\nAny existing headers with the same name will be removed.\n\nThis configuration will add a foo header to the request with a value of bar and a quality of 0.8.\nAny existing request headers with the same name will be removed.\nIt will also add a baz header to the response with a value of qux and a quality of 0.4.\nAny existing response headers with the same name will not be removed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/api-validator.html", "title": "8.6.2.0 | Filters | API Validator Filter", "content": "\nThe API Validator filter validates all requests against a configured Web Application Description Language (WADL) file.\nFor example, if a request to the origin service is missing the tenant ID in the URI, but the origin service requires the tenant ID to be there, then the request will be rejected before it reaches the origin service.\nThe API Validator filter can also be configured to validate the content of the request body against an XML Schema Definition (XSD) or JSON Schema referenced as a grammar in the WADL.\n\nA working knowledge of WADL\u2019s and XSD\u2019s/JSON Schemas will make the configuration of this filter much easier.\nTherefore, it is recommended that you read up on these subjects before attempting to use this filter.\nA good tutorial on XSD 1.1, including a comparison of XSD 1.1 and XSD 1.0, is located at:\n\nMost of the ideas described in this conference session are implemented in this filter:\n\nThis filter does not require any request headers.\n\nHowever, the configuration can require specific headers and/or values be present in order to successfully exit this filter.\nThe most common use of a request header by this filter is for Role-Based Access Control (RBAC) using the X-Roles header populated by the Keystone v2 filter.\n\nThis filter has no dependencies on other filters and can be placed wherever it is needed in the filter chain.\n\nHowever, due to the nature of this filter it is typically placed early in the filter chain immediately after any authentication filters.\n\nThis filter only creates/modifies request headers when configured for Delegation.\nIf delegation is enabled, then the X-Delegated header is created.\nThis is mainly intended for use by the Highly Efficient Record Processor (HERP) filter and Delegation Response Processor (DeRP) filter for internal delegation processing within Repose.\nHowever, it can be exposed to the origin service under certain configurations.\n\nThis filter does not modify the request body.\n\nThis filter is not strictly required by any other filters.\n\nThis filter does not modify the response body.\n\nThis filter does not create/modify any response headers.\n\nThrough the use of the rax:code WADL extension, any of these default codes can be overridden to any value.\n\nThis configuration is the most basic example of this filter\u2019s configuration.\n\nEven though multiple validator element definitions and the role and default attributes on each are deprecated, the easiest way to future proof new configurations is to:\n\nThis configuration expands the basic example in order to show off all of the features of this element.\n\nTo place this filter in Delegation mode, add the delegating element to the filter configuration with an optional quality attribute that determines the delegating priority.\n\nThis configuration shows the deprecated, but currently legal, multi-validator definition as well as an embedded WADL which is also deprecated.\n\nThis filter is based on the API Checker library.\n\nThis component reports the following metrics to the Metrics Service:\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/attribute-mapping-policy-validation.html", "title": "8.6.2.0 | Filters | Attribute Mapping Policy Validation filter", "content": "\nThis filter will validate attribute mapping policies in requests to the origin service.\n\nThe origin service is expected to be an Identity service.\nThis filter will only take action if the HTTP request method is PUT.\n\nThis filter has no configuration.\n\nThis filter has no dependencies on other filters.\n\nThis filter does not create/modify any request headers.\n\nThis filter does not modify the request body.\n\nThis filter does not modify the response body.\n\nThis filter does not create/modify any response headers.\n\nSince this filter will act on all requests it receives, it is recommended to only add this filter to the filter chain for endpoints that expect an attribute mapping policy body.\nThe System Model provides a mechanism to construct conditional filter chains based on the request URI.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/body-extractor-to-header.html", "title": "8.6.2.0 | Filters | Body Extractor to Header Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nRemove this section if not needed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/body-patcher.html", "title": "8.6.2.0 | Filters | Body Patcher Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nRemove this section if not needed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/compression.html", "title": "8.6.2.0 | Filters | Compression Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nRemove this section if not needed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/content-type-stripper.html", "title": "8.6.2.0 | Filters | Content Type Stripper Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nRemove this section if not needed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/cors.html", "title": "8.6.2.0 | Filters | CORS Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\nThe Cross-Origin Resource Sharing (CORS) filter allows Repose to manage CORS requests without the origin service needing to understand CORS.\nFor an introduction to CORS, see the CORS Overview section below.\n\nBefore enabling the CORS filter, you should be familiar with the CORS specification and the associated security implications.\nEnabling CORS can increase an endpoint\u2019s exposure.\nConfiguring CORS improperly could expose Cross-Site Request Forgery (CSRF) vulnerabilities in the origin service that were previously hidden by not supporting CORS.\n\nThe presence and values of certain headers will indicate what kind of request is being made.\nAll of these headers will be supplied by the client making the request.\n\n* If the Origin header matches the original Host header in the request, it will be considered a non-CORS request.\nSee the Origin Header section for more details.\n\nThe CORS filter should be one of the first filters, if not the first filter, in the filter chain in order to properly handle CORS Preflight Requests and to properly handle exposing response headers in CORS Actual Requests.\nIf you want to rate limit CORS Preflight Requests, you can add the following filters before the CORS filter in the filter chain:\n\nThis Rate Limiting filter would be in addition to any Rate Limiting filter you may already have in place.\nThe first Rate Limiting filter would filter only by IP address, and the second Rate Limiting filter would continue to rate limit the way it\u2019s currently set up.\n\nThis filter does not create/modify any request headers.\n\nThis filter does not modify the request body.\n\nThis filter is not strictly required by any other filters.\n\nThis filter does not modify the response body, but it will set it in certain early termination conditions.\nSee the [Response status codes] section for more details.\n\nThe filter will add the following headers to the response when the request is allowed to proceed:\n\nThe following headers will be added to the response when the request is rejected by this filter:\n\nThese are the conditions in which the CORS filter will stop processing the request and immediately return a response:\n\nA basic CORS configuration would allow all origins to use any standard HTTP method on all resources.\n\nIf you configure an origin regex of .* or any other regex that could allow untrusted origins, you may want to consider securing your API from CSRF exploits.\n\nTo limit which origins are allowed to initiate a CORS request to your API, you can specify a literal value or a regular expression that the Origin header must match in order to proceed with the request.\n\nIf specific resources support additional HTTP methods, you can configure this per-resource using a regex to specify the path or paths.\nThe resource configuration is processed in the configured order, so the first path regex to match the request URI will be used in conjunction with the global allowed-methods configuration.\nThis is used to determine the complete list of allowed methods to return in response to a CORS Preflight Request and to determine whether or not a CORS Actual Request is allowed to proceed past this filter.\n\nThis is not a substitution for authorization.\nRequests that do not contain the Origin header are not CORS requests and completely bypass this validation.\n\nUsing this configuration, you would see the following behavior:\n\nThis is an example configuration with notes on all of the required and optional elements and attributes.\n\nCORS is not a security feature.\nIt is a mechanism for informing clients (e.g., web browsers) of conditions when client-side security may be slightly relaxed in certain circumstances.\nThat is, the security lies completely within the client.\nSimply leaving out the Origin header in the request completely bypasses the CORS spec (and thus this filter).\nYou should continue securing your API in other ways using proper authentication and authorization mechanisms.\n\nFor security purposes, web browsers follow the Same-Origin policy.\nIf a user were to visit a website containing malicious code, the web browser would prevent the malicious code from trying to send requests to different websites on the user\u2019s behalf.\nThis is especially useful when the user is authenticated on those other websites.\nHowever, sometimes a website needs to be able to get data or perform an action on a different website, but how can the client know which websites allow this and under what circumstances?\nThis is where CORS comes in.\n\nInstead of the web browser immediately dropping any attempt to send a request to a third-party server, it can send the request to that server with CORS headers to see if the server trusts the origin server.\nThe address of the origin server is sent in the Origin header.\nIf the response from the third-party server does not contain the appropriate CORS headers (i.e., the server is not CORS aware) or if the CORS headers indicate the Origin is not allowed to send requests to it, the browser will drop the response (i.e., the client-side code from the origin server will not get to see the contents of the response from the third-party server).\n\nEven though the web browser will prevent the client-side code from seeing the response from the third-party server, the request may have still been processed by the third-party server.\nTo mitigate this issue, the web browser will send a CORS Preflight Request to the third-party server to first verify that the Origin and HTTP method are allowed (among a few other things) before sending the CORS Actual Request.\nIf the response to the CORS Preflight Request indicates the CORS Actual Request would not include the appropriate CORS headers, the web browser will not proceed with sending the CORS Actual Request.\n\nBecause the CORS Preflight Request is asking if a CORS Actual Request would be allowed and not for the request to actually be processed, this type of request is completely handled by the CORS filter in Repose.\nNo other filters after the CORS filter will process the request, and the request will not reach the origin service.\n\nA web browser may choose to skip sending a CORS Preflight Request if the HTTP method is GET, HEAD, or POST, the request headers do not include anything other than Accept, Accept-Language, and Content-Language, and the request does not require any cookies, HTTP authentication, nor use of any client-side SSL certificates.\nOtherwise, the web browser must make a CORS Preflight Request.\nFor example, if your origin service requires an X-Auth-Token header, the web browser will always send a CORS Preflight Request before sending the CORS Actual Request.\n\nSome web browsers (e.g., Chrome and Safari) will send the Origin header for same-origin (i.e., non-CORS) requests in addition to CORS requests which is technically allowed under RFC 6454.\nThis is typically not a concern for servers handling CORS because the unnecessary inclusion of CORS headers will be ignored by the client if they are not needed to process the response.\nBecause Repose has the added ability to reject requests with unapproved origins, additional logic is required to differentiate between CORS requests and same-origin requests when the Origin header is present.\n\nRequests are considered same-origin requests when the Origin header matches the original Host header set by the client according to the comparison rules in RFC 6454 Section 5.\nIf the X-Forwarded-Host header is present in the request, the first value will be used as the host.\nIf the header is not present or it cannot be parsed as a URI (when the URI scheme is prepended to it), then the Host header will be used instead.\nThis check is not performed for CORS Preflight Requests since web browsers should not be sending a CORS preflight header for a same-origin request.\n\nIf a proxy server sitting between the client and Repose rewrites the Host without updating the X-Forwarded-Host header with the original value, Repose will not be able to correctly identify same-origin requests coming from that client.\nThis may result in requests from that client being incorrectly rejected on the basis that they are CORS requests when they may in fact be same-origin requests.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/derp.html", "title": "8.6.2.0 | Filters | Delegation Response Processor (DeRP) Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nRemove this section if not needed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/destination-router.html", "title": "8.6.2.0 | Filters | Destination Router Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nThis component reports the following metrics to the Metrics Service:\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/echo.html", "title": "8.6.2.0 | Filters | Echo Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nRemove this section if not needed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/exception.html", "title": "8.6.2.0 | Filters | Exception Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nRemove this section if not needed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/forwarded-proto.html", "title": "8.6.2.0 | Filters | Forwarded Protocol Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nRemove this section if not needed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/header-normalization.html", "title": "8.6.2.0 | Filters | Header Normalization filter", "content": "\nThe Header Normalization filter removes configured headers from a request and/or response.\nNormalization is the process of modifying or standardizing content to optimize the flow of information.\nThe Header Normalization filter normalizes the headers of the request by performing two separate functions.\nThe filter uses blacklisting to prevent specific headers and it uses whitelisting to allow only approved headers from continuing down the filter chain.\nThe headers can be matched by URI regular expression (uri-regex) and/or HTTP method type (http-methods).\n\nThis filter does not require any request headers.\n\nThis filter has no dependencies on other filters and can be placed wherever it is needed in the filter chain.\nHowever, due to the nature of this filter it is typically placed early in the filter chain.\n\nChanges to request headers vary based on configuration.\n\nThis filter does not modify the request body.\n\nThis filter is not strictly required by any other filters.\n\nThis filter does not modify the response body.\n\nChanges to response headers vary based on configuration.\n\nThis filter does not modify the response code.\n\nThis configuration shows how to use the Whitelist feature of the Header Normalization filter.\nIt will remove all other headers except those required to initiate an authentication sequence.\n\nThis configuration shows how to use the Blacklist feature of the Header Normalization filter.\nIt will remove only the specified headers from all responses.\n\nThis configuration is a more complex example.\n\nThis component reports the following metrics to the Metrics Service:\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/header-translation.html", "title": "8.6.2.0 | Filters | Header Translation Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nRemove this section if not needed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/header-user.html", "title": "8.6.2.0 | Filters | Header User Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nRemove this section if not needed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/herp.html", "title": "8.6.2.0 | Filters | Highly Efficient Record Processor (HERP) Filter", "content": "\nThe Highly Efficient Record Processor (HERP) filter logs an event for each API request.\nThese logs provide information regarding the processing of each request.\nThe logs can be inspected to view the usage of a service and to perform auditing.\nEvents are recorded even if the API request is rejected by Repose before reaching the origin service.\n\nThis filter has no dependencies on other filters and can be placed wherever it is needed in the filter chain.\n\nIn order for the HERP filter to process and record every request, no preceding filter in the filter chain may write a response.\nTo prevent short-circuiting without changing behavior, delegation has been added to many Repose filters.\nSee Delegation in Repose for more details.\n\nThis filter does not create/modify any request headers.\n\nThis filter does not modify the request body.\n\nThis filter is not strictly required by any other filters.\nHowever, the DeRP filter commonly follows the HERP filter.\n\nThe HERP filter will not process responses sent from preceding filters.\nThe DeRP filter can be used to perform delegation.\nPlace the DeRP filter after the HERP filter so that responses sent by any preceding filters are delegated.\n\nThis filter does not modify the response body.\n\nThis filter does not create/modify any response headers.\n\nThis filter does not modify the response code.\n\nTo use the HERP filter, you need to:\n\nThe HERP filter allows user-configurable filtering along with optional pre and post log identifiers.\n\nEach filterOut block contains all of the criteria required for a single filter.\nIf any of the individual criterion in the match elements contained within a filterOut element fail, then that filter fails and it goes on to evaluate the next one.\nIf any of the filterOut blocks fully match, then the event is filtered and not logged to the post-filter log.\nIn other words, the match elements are logically AND\u2019d and the filterOut blocks are logically OR\u2019d.\n\nThe {{methodLabel}} variable value is provided by the api-validator filter.\nIf you aren\u2019t using that filter, {{methodLabel}} will return empty string.\n\nThe HERP filter allows user-configurable filtering along with optional pre and post log identifiers.\n\nEach filterOut block contains all of the criteria required for a single filter.\nIf any of the individual criterion in the match elements contained within a filterOut element fail, then that filter fails and it goes on to evaluate the next one.\nIf any of the filterOut blocks fully match, then the event is filtered and not logged to the post-filter log.\nIn other words, the match elements are logically AND\u2019d and the filterOut blocks are logically OR\u2019d.\n\nFor information about using the Flume with the HERP filter for user access event recording, see CF Flume Sink for more details.\n\nIn the template element, certain template keys may be used to add dynamic content to the text being logged.\nAny valid key enclosed in brackets (i.e., {{<key>}}) will be replaced, brackets included, by the value associated with that key at runtime.\nNote that key names are case sensitive.\nA list of supported keys follows:\n\nThe HERP filter also provides helper functions to the templating engine.\nThese helpers work like the keys above, but take some input.\nFor example, assuming the HTTP request method is a GET, {{cadfMethod requestMethod}} would be replace by \"read/get\".\nThe following helpers are available:\n\nIf you expect heavy usage, you should use a logging tool, such as Logstash, for managing events and logs and should not write events to files.\nEven if you rely on auditing, it is not recommended that you use the file system with the audit logs.\nRepose has developed CF Flume Sink to eliminate disk space and log file issues.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/ip-user.html", "title": "8.6.2.0 | Filters | IP User Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nRemove this section if not needed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/iri-validator.html", "title": "8.6.2.0 | Filters | IRI Validator Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nRemove this section if not needed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/keystone-v2-basic-auth.html", "title": "8.6.2.0 | Filters | Keystone v2 Basic Auth Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nRemove this section if not needed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/keystone-v2.html", "title": "8.6.2.0 | Filters | Keystone v2 Filter", "content": "\nProvides a mechanism for authenticating incoming requests with the OpenStack Keystone v2 Identity service.\n\nThis filter has no dependencies on other filters.\n\nHowever, it is a good practice to prevent spoofing of identities by putting the Header Normalization filter before any authentication and/or authorization filters so that it can remove any headers that would be populated by them.\n\nThe following headers are created using the information returned from the authentication service:\n\nThe following headers are added for use by the Rate Limiting filter:\n\nIf the set-catalog-in-header attribute is true, then the service catalog from the authentication service is a base 64 encoded and placed in the following header:\n\nThe Keystone v2 Identity service supports impersonation.\nWhen an impersonation token is validated, the authentication service will return identifying information for the impersonator.\nThis information allows impersonated calls to be tracked (e.g., via SLF4J HTTP Logging filter).\nThe origin service can also determine when a request is impersonated and who the impersonator is.\nThe information is placed in the following headers:\n\nThe Keystone v2 Identity service also has other attributes it provides when a token is validated.\nIf any of this information is provided, then it will be passed in the following headers:\n\nIf delegation is enabled, then the X-Delegated header is created.\nThis is mainly intended for use by the Highly Efficient Record Processor (HERP) filter and Delegation Response Processor (DeRP) filter for internal delegation processing within Repose.\nHowever, it can be exposed to the origin service under certain configurations.\n\nThis filter does not modify the request body.\n\nThis filter is not strictly required by any other filters.\nHowever, the following filters may be useful:\n\nThis filter does not modify the response body.\n\nSuccessful (2xx)\n\nRequest continues\n\nRequest continues\n\nRequest continues\n\n400\n\n500\n\n500\n\n500\n\n401\n\n500\n\n500\n\n500\n\n401\n\n401\n\n401\n\n403\n\nThe admin token is unauthorized.\n\n500\n\n500\n\n500\n\n404\n\n401\n\n401\n\nRequest continues\n\n405\n\n500\n\n500\n\n500\n\n413\n\n429\n\nThe Keystone v2 Identity service rate limited the Repose instance.\n\n503\n\n503\n\n503\n\n500\n\n501\n\n502\n\n503\n\nThe Keystone v2 Identity service failed to process the request.\n\n502\n\n502\n\n502\n\nThis configuration will provide the basic headers using self-validating tokens.\n\nThis configuration will use an admin account instead of using the self-validating tokens feature.\n\nIF either a username OR a password is supplied, THEN you must provide both a username AND a password.\n\nThis configuration is an example using the identity-service element\u2019s configuration attributes that have not yet been shown in an example.\n\nIn some cases, you may want to delegate the decision to reject a request down the chain to either another filter or to the origin service.\nThis filter allows a request to pass as either confirmed or indeterminate when configured to run in delegating mode.\nTo place the filter in delegating mode, add the delegating element to the filter configuration with an optional quality attribute that determines the delegating priority.\nWhen in delegating mode, the filter sets the X-Identity-Status header with a value of confirmed when valid credentials have been authenticated by the Keystone v2 Identity service and to indeterminate when the credentials are not.\nThe the X-Identity-Status header is in addition to the regular X-Delegated delegation header being created.\n\nYou can configure this filter to allow no-op processing of requests that do not require authentication.\nFor example, a service might want all calls authenticated with the exception of the call for WADL retrieval.\nIn this situation, you can configure the whitelist as shown in the example below.\nThe whitelist contains a list of Java Regular Expressions that Repose attempts to match against the full request URI.\nIf the URI matches an expression in the white list, then the request is passed to the origin service.\nOtherwise, authentication is performed against the request.\n\nThis filter caches authentication tokens.\nThe length of time that tokens are cached is determined by the Time To Live (TTL) value that is returned from the authentication service (e.g., the Keystone v2 Identity service) during token validation.\n\nYou can configure alternate maximum TTL for caching of authentication tokens, groups, and endpoints.\nIf you specify the token element value in the configuration file, this value is used when caching tokens, unless the token TTL value provided by the Keystone v2 Identity service is less than the token-cache-timeout value.\nThis method prevents Repose from caching stale tokens.\nIf the token\u2019s TTL exceeds the maximum allowed TTL value (2^31 - 1), the maximum allowed TTL is used.\n\nEach timeout value behaves in the following way:\n\nYou can configure this filter to use an Atom Feed for cache expiration.\nThis configuration blocks malicious users from accessing the origin service by repeatedly checking the Cloud Feed from the authentication service.\nTo set up this filter to use Cloud Feeds for cache expiration, you will need to enable the Atom Feed Consumption service in the System model, configure the Atom Feed Consumption service, and configure this filter with which feeds to listen to.\n\nThe Rackspace infrastructure uses Cloud Feeds (formerly Atom Hopper) to notify services of events.\nThis is not default OpenStack behavior, and may require additional services for use.\nA list of Rackspace Cloud Feeds endpoints for Identity Events can be found at\nthe internal Rackspace Wiki page linked here.\n\nTenant ID Validation is the capability of this filter to parse a tenant ID out of a request URI and validate it against the tenant ID(s) available in the response token from the Keystone v2 Identity service.\n\nIf the Default Tenant and the URI Tenant are the same, then the highest quality between the two will be used.\n\nIf the validate-tenant element is not present, then this filter will not attempt to validate a Tenant ID from the URI.\n\nThe uri-extraction-regex will be used to populate the X-Tenant-ID header with the value extracted by the capturing group.\n\nIf Tenant ID Validation is enabled, then a list of roles that are allowed to bypass this check can be configured.\nThese configured roles will be compared to the roles returned in a token from the Keystone v2 Identity service, and if there is a match, the Tenant ID check will be skipped.\n\nIf endpoint authorization is enabled, then the user must have an endpoint in their catalog meeting the defined criteria.\n\nThe public-url, region, name, and type attributes are all optional and can be combined as needed to achieve the desired restrictions.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/merge-header.html", "title": "8.6.2.0 | Filters | Merge Header Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nRemove this section if not needed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/openstack-identity-v3.html", "title": "8.6.2.0 | Filters | Openstack Identity v3 Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nRemove this section if not needed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/rackspace-auth-user.html", "title": "8.6.2.0 | Filters | Rackspace Auth User Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\nThe Rackspace Auth User filter is for usage in Repose instances that sit in front of Keystone v1 and v2 deployments.\nIt\u2019s meant to be used for login requests to capture username for both rate limiting and user access events.\n\nThis filter has no dependencies on other filters.\n\nThis filter does not modify the request body.\n\nThis filter needs to appear in the filter chain before any of the filters that need the information that derives and provides.\nThat means the rate limiting filter when rate limiting, and herp filter when doing user access events.\nWhen doing both the order should be:\n\nFor further details about the reasoning behind this ordering see user access events.\n\nThis filter does not modify the response body.\n\nThis filter does not create/modify any response headers.\n\nThere are no cases where this filter will terminate further processing of the filter chain.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/rate-limiting.html", "title": "8.6.2.0 | Filters | Rate Limiting Filter", "content": "\nThe Rate Limiting filter can be used to limit the number of requests that make it through Repose to specified resources belonging to the origin service.\nBy imposing a rate limit, an operator can prevent the origin service from being flooded by requests, thereby bounding the potential for congestion or contention.\n\nAdditionally, this filter can expose rate limiting data by allowing users to query rate limits.\nWith accessible rate limiting data, a user can determine the number of requests they are allowed to make per period of time to various resources.\n\nSee Additional Information for more details on how rate limiting is performed.\n\nThis filter uses the quality parameter of header values to determine the user and group(s) provided in the request.\nThe value(s) with the highest quality will be used, while all other values will be ignored.\nIn the case of the X-PP-User header, only the first of the highest quality values will be used.\n\nThis is useful when an operator desires to employ multiple authentication/identity mechanisms.\n\nStrictly speaking, there is not a hard requirement for any filter to precede this filter.\nHowever, it is strongly recommended to utilize the following filters ahead of this filter.\n\nThis filter does not modify the request body.\n\nThis filter is not strictly required by any other filters.\n\nThis filter will only modify the response body if this filter is configured with a request-endpoint.\nIn that case, in response to requests made to the request-endpoint, this filter will populate the response body with details of the current state of limits which apply to the provided user with the provided group(s).\n\nSee Querying Limits for more details.\n\nIn this example, we have configured this filter to allow users to query their limits.\nProvided below are sample requests to give you a better idea of what that looks like.\n\nThis configuration provides per-user limits, global limits, and an endpoint to query limit data.\n\nA limit group is just a group containing one or more limit(s).\nThe motivation behind limit groups is to provide a way of applying different limits to different types of users.\nThe limits that will be applied to the request are the limits in the limit group configured with a group that matches a value in the X-PP-Groups header.\nIf no limit group matches the request, the default limit group will be used.\n\nWhen a limit in a group is reached, succeeding limits within the same limit group will never be applied.\nIn other words, the most restrictive limit will prevent updates to succeeding limits.\nPreceding limits within the group will continue to apply (i.e., continue to increment).\n\nOnly the limits in the first limit group to match the request are applied.\n\nA limit is the number of requests per unit of time that are allowed to pass through Repose.\nLimits are applied selectively to requests matching certain criteria such as a request\u2019s HTTP method and query parameters.\nMultiple rate limits that match the same request will all apply.\nA limit is reached when a user has sent a number of requests equal to the value of the limit within the span of one unit (configurable on the limit) of time.\nIf a limit has been reached, this filter will prevent requests from passing through Repose.\nIf a limit has not been reached, the request will pass through this filter.\nLimits will reset after the configured unit of time has passed.\n\nGlobal limits are very similar to normal Limits, except that they are applied to all requests, irrespective of the user making the request.\nThat is, global limits can protect the end service as a whole rather than just from individual users.\nFor example, if a service is known to only handle up to 500 requests per second in total, a global rate limit can be set to 500 requests per second to prevent further requests from reaching and compromising the origin service.\nAny request which breaks that limit will receive a response with status code 503.\n\nGlobal limits are not currently queryable via the request-endpoint.\n\nThis is the algorithm used to determine whether or not a limit has been reached.\nIn this algorithm, a time unit is considered discrete and independent from other units.\nTherefore, only requests that occur during such a time unit are counted towards the limit.\nOnce the end of a time unit is reached, the count toward a limit will be reset.\nThis is in contrast to a leaky bucket rate limit, wherein time units are continuous.\n\nIt is important to note that, with this approach, it is possible that 2x - 1 (where x is the configured limit value) requests will pass through this filter over the period of one time unit.\nIf that occurs, however, fewer requests will be allowed to pass through surrounding time units.\nWhich is to say that, on average, the configured rate limit of x will be enforced.\n\nConsider the following example.\nFive requests are allowed per minute for each time-block, but the one-minute window that lands in between the two units has seven requests.\nThis shows that limits may be broken for a given window of time, however, across multiple units of time, the allowed requests average less than or equal to five requests per minute.\n\nThis filter tracks limits by user, and consequently, requires a user be provided when querying limits.\nThe exception is global limits, however, since global limits are not currently query-able, they will be omitted from this explanation.\nTo query a limit, a GET request should be made to the request-endpoint.\nIf no request-endpoint is defined, then querying limits is not possible.\nAs always, requests must include the X-PP-User header, and may include the X-PP-Groups header.\nThe limit details returned from the request-endpoint will be for the limits in the limit group that matches a provided group as they apply to the provided user.\n\nThe limit details themselves will be presented in either XML or JSON format.\nIf no Accept header is present on the request, or if the Accept header has no value, the JSON format will be returned as the default.\nOtherwise, the returned format will be determined based on the Accept header specification defined in Section 14 of RFC 2616.\nIf the limit query request does not accept at least one of the supported media types, a 406 response will be returned.\n\nTake a look at the Querying Limits Example to see this feature in action!\n\nThe set of absolute limits is comprised of the set of limits defined in this filter\u2019s configuration and the limits imposed by the origin service.\nThese limits will only be returned if include-absolute-limits on the request-endpoint is set to true.\nOtherwise, only the limits defined in this filter\u2019s configuration will be returned.\n\nTo retrieve limits from a origin service, a request will be made through the Repose filter chain to the origin service.\n\nIf this filter is configured to use the Distributed Datastore, and the Distributed Datastore service is unable to communicate with other nodes (e.g., during a rolling upgrade to Repose), then the Distributed Datastore service will fall back on the local datastore.\nConsequently, rate limits may not be tracked correctly during the transition from the Distributed Datastore to the local datastore or vice-versa.\nTo be more precise, when Distributed Datastore nodes are unreachable, limit data cannot be be retrieved, and so new limits are created in the local datastore.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/saml-policy.html", "title": "8.6.2.0 | Filters | SAML Policy Translation Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\nThis filter takes a SAML Response in the post binding, decodes it, adds a new translated assertion to it and then signs the entire response.\nIt\u2019ll attempt to locate a policy to use for the translation based on the assertion issuer.\n\nThis filter has no dependencies on other filters.\n\nThe request body will be decoded and replaced with an xml version if the content type is application/x-www-form-urlencoded.\nIf issuer isn\u2019t in the configured bypass list indicating the use of the legacy v1.0 API, then the v2.0 API is assumed and a new assertion will be generated based on the matching issuer policy with http://openrepose.org/filters/SAMLTranslation as the issuer.\nAdditionally the SAML Response will be signed with the configured credentials.\n\nThis filter is not strictly required by any other filters.\n\nIf the legacy v1.0 API is in use, then the response body is not modified.\nHowever, if the v2.0 API is in use, then the response body will be updated with the additional attributes specified in the original SAML Response issuer\u2019s configured policy.\n\nThis filter does not create/modify any response headers.\n\nThis configuration exercises all the capabilities of the filter.\n\nThe Keystone user account configured for use in this filter must possess a role of identity:identity-provider-read-only.\nIt is recommended to use a uri-regex in your system model to filter traffic to this filter, because it will fail on non-SAML requests.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/scripting.html", "title": "8.6.2.0 | Filters | Scripting Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\nThe Scripting filter enables users to write custom filters for Repose using a variety of scripting languages.\nCustom filters can be used to perform arbitrary processing with access to the bindings described below.\n\nThis filter does not require any request headers.\n\nThis filter has no dependencies on other filters and can be placed wherever it is needed in the filter chain.\n\nChanges to request headers vary based on configuration.\n\nChanges to the request body varies based on configuration.\n\nThis filter is not strictly required by any other filters.\n\nChanges to the response body varies based on configuration.\n\nChanges to response headers vary based on configuration.\n\nChanges to the response code varies based on configuration.\n\nAll supported languages are currently compilable.\n\nAn enumeration of all supported language names (e.g., python and jython) that will be accepted in configuration can be found in the XML schema linked on this page.\n\nBindings are variables defined by the Scripting filter which can be used in scripts.\n\nCurrently supported bindings are detailed by the following table:\n\nInvoking the doFilter method on the filterChain object is necessary to pass the request/response along.\nIf doFilter is not invoked, the scripting filter will return the response object as-is up the filter chain.\nNo later filter nor the origin service will have a chance to process the request.\n\nThe performance of this filter will vary depending on configuration.\n\nFor the simple task of adding a header to a request, this filter performs comparably to the Add Header Filter.\n\nScripts written in a compilable language as shown above will always be compiled.\nThis should dramatically improve performance.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/simple-rbac.html", "title": "8.6.2.0 | Filters | Simple Role Based Access Control (RBAC) Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nRemove this section if not needed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/slf4j-http-logging.html", "title": "8.6.2.0 | Filters | SFL4J HTTP Logging Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nRemove this section if not needed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/translation.html", "title": "8.6.2.0 | Filters | Translation Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nRemove this section if not needed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/uri-normalization.html", "title": "8.6.2.0 | Filters | URI Normalization Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nThis component reports the following metrics to the Metrics Service:\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/uri-stripper.html", "title": "8.6.2.0 | Filters | URI Stripper Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nRemove this section if not needed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/uri-user.html", "title": "8.6.2.0 | Filters | URI User Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nRemove this section if not needed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/url-extractor-to-header.html", "title": "8.6.2.0 | Filters | URL Extractor to Header Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nRemove this section if not needed.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/valkyrie-authorization.html", "title": "8.6.2.0 | Filters | Valkyrie Authorization Filter", "content": "\nThe Valkyrie Authorization filter performs three distinct functions:\n\nCurrently, only JSON bodies are supported.\nIf you would like to request XML support, please contact us!\n\nEach function is optional, and as many or as few as desired can be used.\nAll functions involve making one or more call(s) to the Valkyrie service to ascertain a user\u2019s permissions.\nThe results of these calls are cached to cut down on the traffic generated by repeat requests.\n\nWhile there are no preceding filters that are strictly required, the following filters may be useful:\n\nThis filter does not modify the request body.\n\nThis filter is not strictly required by any other filters.\nHowever, the following filters may be useful:\n\nIf the collection-resources element is configured, this filter will perform culling on the response body.\nCulling is used to restrict the data transmitted to the user from the origin service.\nTechnically, culling is the removal of fields from the response body, and the updating of corresponding field counts.\nCurrently, only JSON content is supported.\n\nThis filter may also remove the response body if culling cannot be completed successfully.\nSee the [Response status codes] section for more details.\n\nFor more information about specific response codes that Repose will receive from the Valkyrie service, please refer to the Valkyrie documentataion.\n\nIf a user has the account_admin role in Valkyrie, when enable-bypass-account-admin is configured to be true (the default is false), the Valkyrie filter will pass the request along regardless of whether or not the device permission check fails.\nCulling will also not be performed when configured in this manner.\nThe Valkyrie filter can add the user\u2019s permissions to the X-Roles header, but it is left to a subsequent filter or the origin service to validate the request.\n\nThis configuration will authorize users against Valkyrie.\n\nThis configuration will authorize non-admin users, translate permissions to roles, cull the response, and delegate any failures.\n\nThe enable-bypass-account-admin attribute applies to users with the role permission account_admin as well as requests with a X-Device-Id `header value containing a device ID to which the user has `account_admin device permissions.\nThis could unintentionally bypass culling.\nA X-Device-Id header should not be added or allowed on requests to endpoints where culling is performed.\n\nThis filter utilizes Keystone to authenticate with the Valkyrie service.\nThe X-Auth-Token header will be copied from the inbound request to Repose to the outbound request to the Valkyrie service.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/filters/versioning.html", "title": "8.6.2.0 | Filters | Versioning Filter", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\n???.\n\nThis configuration will ???.\n\nThis component reports the following metrics to the Metrics Service:\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/api-event-flume.html", "title": "8.6.2.0 | Recipes | API Access Event Recording with Flume", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/basic-authentication.html", "title": "8.6.2.0 | Recipes | Basic Authentication", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/client-authentication.html", "title": "8.6.2.0 | Recipes | SSL/TLS Client Authentication", "content": "\nThis recipe explains how to utilize SSL/TLS Client Authentication in Repose.\n\nSSL/TLS provides an encrypted link between the client and the server, and is the standard for sending private data over the internet.\nYou may want to enable SSL/TLS Client Authentication if part of your infrastructure is in a different datacenter to ensure only cross service traffic can reach your service.\n\nSSL/TLS Client Authentication is being used more and more for communications between different enclaves.\nThis addition to the server based SSL/TLS handshake involves the Client presenting credentials to the Server in the same manner as the Server does to the Client.\nIf the credentials presented by the Client are not trusted, then the Server will sever the connection just as the Client would have if the situation was reversed.\nSince a Client initiates contact with the Server, the Server\u2019s credentials are simply to validate it is who the Client was trying to contact.\nThis is accomplished through Certificate Authorities (CA) and the Trust Hierarchies built into the Public Key Infrastructure (PKI).\nEven though you can optionally add a particular Server\u2019s credentials directly into a Client so that it will implicitly trust a particular Server essentially bypassing the distributed trust mechanism in favor of a more direct one, this is the only way to build a relationship for a Client to a Server.\n\nIn the following steps, the client will refer to the entity sending the request, and the server will refer to the entity receiving the request.\nIf you are setting up client authentication for requests inbound to Repose, then the entity sending the request is the client and Repose is the server.\nIf you are setting up client authentication for requests outbound from Repose to the origin service, then Repose is the client and the origin service is the server.\n\nUsing the JDK provided keytool generate the certificate that the client will use.\n\nAgain, using the keytool export the certificate.\n\nUsing the keytool import client certificate into the server keystore.\n\nWith your certificates in the right spot it\u2019s time to turn authentication on for Valve.\nThis is achieved with a simple tweak to the container.cfg.xml.\n\nTo turn on authenticated communication to your origin service, you\u2019ll need to tweak the default pool in your http client pool config.\nThere is nothing stopping you from similarly tweaking any of your other pools if you have a need to use client authentication in other outbound communication.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/custom-filter-for-repose.html", "title": "8.6.2.0 | Recipes | Custom Filter for Repose", "content": "\nUnfortunately, this page is not going to teach you how to create a custom filter for Repose.\nFortunately, this page is going to direct you to a page that will teach you how to create a custom filter for Repose.\n\nFor a detailed guide on how to create a custom filter for Repose, see our hello world filter project.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/delegation.html", "title": "8.6.2.0 | Recipes | Delegation", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/distributed-rate-limiting.html", "title": "8.6.2.0 | Recipes | Distributed Rate Limiting", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/docker.html", "title": "8.6.2.0 | Recipes | Docker", "content": "\nWith the advent of container technology, Repose can be fully encapsulated and run as a service.\nBy bundling the environment with the software itself, deploying Repose becomes a much quicker, simpler process.\nDocker boasts security through isolation, and when run on platforms with native support, it requires very little overhead.\nTo make everything as easy and versatile as possible, the Repose team will release Docker images on Docker Hub alongside every release of Repose.\n\nTo run Repose in Docker, there are just two basic steps:\n\nTo find out more about Docker, including how to install and operate it, visit the official Docker documentation at:\n\nhttps://docs.docker.com/\n\nAll official, published Docker images for Repose, can be found on Docker Hub at:\n\nhttps://hub.docker.com/r/rackerlabs/repose/\n\nThe Dockerfile used to build the Docker images has been copied below for the sake of convenience.\n\nTo modify and/or build a Repose Docker image from the Dockerfile, follow these steps:\n\nLet\u2019s break that command down and take a closer look at what it is doing:\n\nAfter you have acquired a Repose Docker image, you can run Repose by creating and starting a Docker container from that image.\nFor example, the following command could be use:\n\nLet\u2019s break that command down and take a closer look at what it is doing:\n\nNow if we wanted to, we could change the Docker options that define the environment that Repose will run in.\nIf we wanted to forward the random ports instead of explicitly declaring the port mapping, we could drop the -p 8080:8080 option and pass the -P flag instead.\n\nAfter running that command, you should be able to see Repose running inside a Docker container!\nUse the following command to show all running containers:\n\nOnce running, you may wish to inspect the internal state of the container.\nWell, the default command for the official Repose Docker images will run Repose in the foreground, and as a result, simply attaching to the container with a command like the following will only allow interaction with the Repose process:\n\nInstead, you can use a command like the following to run a new bash session inside of your running container:\n\nIf you need to access Repose log files, the recommended way of doing so would be to mount a Docker volume when starting the container using a command like the following:\n\nYou will notice that this command is very similar to the command provided in the Running section, but with one more option: -v /var/log/repose:/var/log/repose.\nThis option simply mounts the Repose log directory in the container to the same directory on the host.\n\nCustom artifacts are not currently supported by our Docker images.\nIf you would like to deploy custom code in Repose running in Docker, please Contact Us!\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/echo-server.html", "title": "8.6.2.0 | Recipes | Echo Server", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/functional-test-framework.html", "title": "8.6.2.0 | Recipes | Functional Test Framework", "content": "\nThe Repose functional test framework is a testing library provided by the Repose team meant to simplify the process of creating functional tests for features in Repose or its extension components.\n\nThis framework is based on the Spock framework.\nWhile there are features of this framework that are can be used without Spock, it is expected that tests utilizing this framework will be Spock tests.\n\nThe Repose functional test framework is published to an instance of Nexus hosted by Rackspace.\n\nIt is highly recommended that a build system be used to manage this library.\nThe following snippets provide the necessary additions to download this framework with some popular build systems.\n\nThere are two requirements that must be satisfied for this framework.\n\nThe first requirement is that a repose-test.properties file is on the classpath when tests are run.\nThe repose-test.properties file tells that framework what version of Repose, directories, host, and ports to use.\nIt should be in the Java properties file format like the following example:\n\nNot all properties are strictly required.\nIn fact, most properties have reasonable defaults.\nHowever, any property which takes an absolute path should be given a value.\n\nThe second requirement is that the Repose artifacts (e.g., JARs and EARs) must be placed in the directory specified by the repose.home property.\nIf they are located elsewhere, the ReposeValveTest specification will not work.\nHowever, other utilities provided by the framework may still be used.\n\nTo make the most of this framework, tests should be written for the Spock testing framework.\nThe Repose functional test framework provides a base Spock Specification in the form of the ReposeValveTest class.\nThe ReposeValveTest specification provide utilities to populate configuration file templates, start Repose, and search the Repose log.\n\nThe following simple example demonstrates how a Spock test can be written utilizing the Repose functional test framework.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/getting-started.html", "title": "8.6.2.0 | Recipes | Getting Started", "content": "\nRepose is an open-source, RESTful middleware platform that transparently integrates with your existing infrastructure.\nTechnically, it is a pseudo-transparent reverse proxy.\n\nRepose provides highly scalable, extensible solutions to common API processing tasks including authentication, rate limiting, access control, logging, and more.\n\nAdditionally, Repose allows services to use Enterprise Integration Patterns.\n\nRepose takes incoming requests from clients and adjusts them for consumption by services by passing the requests through a series of extensible filters.\nThese filters provide functionality such as authentication, authorization, rate-limiting, and request modification.\nRepose can run as a stand-alone proxy server between the client and the origin service.\nThe Repose instance can be on the same host as the origin service, but it doesn\u2019t have to be.\nThis deployment method, illustrated in the following graphic, is called Valve.\n\nRepose can also run within a servlet container such as GlassFish or Tomcat using the WAR deployment.\n\nYou can decide which configuration works best for you, and you can tweak many of your configurations without having to restart Repose \u2013 it will pick up configuration changes on the fly, making it easy to configure and test.\n\nRepose can be configured to use a distributed data store service where cached information is exchanged across multiple nodes.\nThis makes Repose fault tolerant with proven performance.\n\nRepose provides a series of customizable filters that you can configure to perform a large number of API tasks.\nThe full list of filters is on the Filters page.\nFollowing are some of the most common ones:\n\nAnyone can use Repose!\nIt is an open-source platform for the general public to consume, share, and improve.\n\nTo get Repose, log in to your server and run the Installation commands for your desired environment.\nThen, configure your origin service endpoint in the system model, and you are ready to configure filters and services that work for you.\nWe have many sample configurations that you can use to get started.\nOr, because Repose is open source, you can build your own stacks of reusable software components.\n\nInstallation instructions are provided for Debian package managers (e.g., APT) and RPM package managers (e.g., Yum).\n\nCertain deployment methods will handle environment setup automatically.\n\nThe most common and preferred way to run Repose is as a standalone application using the Valve installation.\nThis installation allows Repose to be executed either as a Linux service (e.g. systemd) or directly from the installed JAR.\nAn alternative would be to run Repose inside an existing servlet container (e.g. Tomcat, GlassFish) using the WAR installation.\n\nWhile Repose can be installed manually, there are other deployment options available.\nHowever, these other methods do require a little more System Administration knowledge which is not covered here.\nSee: Deployment\n\nThis is the most common setup and is detailed on the Valve Installation page.\n\nAfter installing it this way, consult the Running Valve page for details on starting and stopping Repose.\n\nInstructions for installing the WAR are on the WAR Installation page.\n\nAfter installing the WAR, there is additional setup to get everything working with Tomcat.\nSee Tomcat Setup for more details.\n\nSee GlassFish Setup for more details.\n\nSee HTTP container attributes\n\nOnce you know how you\u2019ll want to configure Repose, you may want to automate the deployment using a configuration management tool or reusable container.\n\nIf you don\u2019t already have a Linux environment ready, you can use Vagrant to easily create a new virtual machine running the Linux distribution of your choice.\nFor more details, see: Vagrant\n\nDocker and Repose make a fantastic team together.\nFor more details, see: Docker\n\nThere is an unsupported starter module in the GitHub repository rackerlabs/puppet-repose.\n\nThere is an unsupported starter cookbook in the GitHub repository rackerlabs/cookbook-repose.\n\nIf you\u2019re ready to dive into configuration, see Configuration for more details.\nWe also have a series of Recipes that will walk you through some of our common use cases.\n\nRepose has been battle tested in production environments and in our performance testing environments.\nSee Performance Best Practices for more details.\n\nFor further information on common configuration scenarios, visit our Recipes page.\n\nFor details on common troubleshooting techniques, visit our Troubleshooting page.\n\nFor a list of frequently asked questions and answers, visit our FAQ page.\n\nContact us! We would be happy to address any questions, comments, or concerns with anything having to do with Repose!\n\nIf you wonder what we\u2019ve been working on lately, visit our release notes.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/glassfish-setup.html", "title": "8.6.2.0 | Recipes | Glassfish Setup", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\nThis page describes how to run the Repose WAR in a Glassfish container.\n\nMake sure to install the Repose WAR first!\n\nIN PROGRESS\n\nIN PROGRESS\n\nIN PROGRESS\n\nIN PROGRESS\n\nIN PROGRESS\n\nRepose needs two parameters set in order to start with an optional third parameter to set the location of the config directory.\n\nIN PROGRESS\n\nAlternatively, the web.xml file within the war itself can be modified to include the following:\n\nRepose can use internal dispatch (within the Glassfish container) to access your deployed WARs.\n\nFor example, if you had sample.war deployed, you could set the configured root-path to /sample and then access it as if it was on the root path (e.g. curl localhost:8080 would point to localhost:8080/sample/).\n\nIN PROGRESS\n\nIN PROGRESS\n\nYou can use curl or HTTPie to send a request to Glassfish.\n\nIf you are using any of the filters that can impact the body of your request or response, and that body is JSON, you may see unexpected behavior.\nThis behavior stems from the fact that Glassfish ships with a different version of certain Jackson libraries than Repose, and the differing versions collide.\nDue to the way Java handles class loading, this can lead to weird cases where some of the classes are loaded from our newer version and some from Glassfish\u2019s older version.\nThis will cause `NoClassDefFoundException`s as it\u2019s looking in the wrong spot for some classes.\nGlassfish does has a configuration to resolve this problem; this configuration tells Glassfish to not do the normal parent delegation of class loading, but to instead check the applications classpath first and then go up the parent classloader chain if it fails to find the needed classes.\nThis requires the addition of the following glassfish-web.xml:\n\nFor more information, see: here.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/http-container-attributes.html", "title": "8.6.2.0 | Recipes | HTTP Container Attributes", "content": "\nThis page lists container supported HTTP attributes and defaults so that we can understand the limitations using those containers.\n\n(http://tomcat.apache.org/tomcat-6.0-doc/config/http.html#Common_Attributes)\n\n(http://docs.codehaus.org/display/JETTY/Configuring+Connectors)\n\n(http://docs.oracle.com/cd/E19798-01/821-1753/auto126/index.html)\n\n(http://httpd.apache.org/docs/2.2/mod/core.html#limitrequestfieldsize)\n\nSometimes, depending on headers added by Repose, the default container limits can be exceeded.\nIf Repose is deployed as Root.WAR in a container and the header size limit is exceeded, then Repose will respond to the client with the same response code that was received from origin service.\n\nTwo example scenarios when it can exceed header size limit are:\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/performance-best-practices.html", "title": "8.6.2.0 | Recipes | Performance Best Practices", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/preventing-xml-bomb.html", "title": "8.6.2.0 | Recipes | Preventing XML bomb attacks", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/quick-setup.html", "title": "8.6.2.0 | Recipes | Quick Setup", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/rate-limiting.html", "title": "8.6.2.0 | Recipes | Rate Limiting", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\nRate limiting can be configured to use any of the datastore types to store rate limiting information for users.\nBy default, rate limiting will use the distributed datastore (hash-ring) if available.\nIf no distributed datastores are available, then rate limiting will use the local datastore.\n\nIn the following example, the Repose instance with the node id of node1 will launch a Distributed Datastore service which will listen on port 9999.\nThe Repose instance with the node id of node2 will launch it\u2019s own Distributed Datastore service which will listen on port 7777.\nWith allow-all set to false, a host that is not in the cluster cannot communicate with the Distributed Datastore.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/role-based-access-control.html", "title": "8.6.2.0 | Recipes | Role Based Access Control", "content": "\nYou can implement Role-Based Access Control (RBAC) with Repose with the Header Normalization, the Authorization, and the API Validator filters.\nThis guide takes you through the process of setting up RBAC with Repose.\n\nTo prevent users from submitting their own roles, you will need to blacklist headers using the Header Normalization filter.\n\nPlease refer to the Header Normalization filter documentation for more information about the available configuration options.\n\nThe Authentication filter will grab the user\u2019s roles from their authentication token and return those roles to Repose.\n\nPlease refer to the Keystone v2 filter documentation for more information about the available configuration options.\n\nThere are two mechanisms for doing the authorization side.\nIf your API is minimal or your just getting started with it, then you might find the Simple RBAC filter most useful.\nIt uses a very simple Domain Specific Language (DSL) that is similar to what other tools use for this basic mechanism.\nIf on the other had your API is large and/or your authorizations are complex, then you will need the heavy lifting of the API Validation filter.\nSince the Simple way is very self explanatory, we will only dive into the more complex way here.\n\nYou will do most of your RBAC configuration here.\n\nWe recommend that you build a table similar to the example below that contains endpoints and the roles that you wish to allow access to those endpoints.\n\nFrom here you have to decide which filter you want to use.\nThere are two options and they both use the same underlying mechanism for enforcement.\nThe only real difference between them is the first option is simple and easy, while the second option has more features which require a little extra configuration.\n\nThe Simple RBAC filter is configured using a Domain Specific Language (DSL) similar to the table above.\n\nThe best part about this filter is that if your API grows or simply becomes to complex for the Simple RBAC filter, then you can easily move to the full API Validator filter later.\nThere is even a setting available to save your Simple RBAC filter configuration in a manner that you can use it immediately with the API Validator filter.\n\nPlease refer to the Simple RBAC filter documentation for more information about the available configuration options.\n\nIf your API is complex or you simply need or are already using some of the extra features available in the API Validator filter, then this is the choice for you.\n\nWhen the enable-rax-roles attribute for the API Validator filter is set to true, the check-headers attribute will also be enabled regardless of your setting.\n\nIn the WADL, include rax:roles with appropriate values to ensure access is controlled as expected.\nWhen defining rax:roles at the resource level, be aware that all sub-resources and methods will inherit the roles allowed at the resource level.\nMultiple roles can be specified by separating the role names with a space.\nIf multiple roles are authorized for a resource and method, the user must have one of the allowed roles but is not required to have all roles.\nExample API Validator filter configuration for RBAC.\nThe following example shows a section of the API Validator filter and WADL that is configured for RBAC.\n\nWith the above WADL and API Validator filter configuration, the following behavior will apply with a request with a user that has the a:observer role.\n\nPlease refer to the API Validator filter documentation for more information about the available configuration options.\n\nThe status codes returned by authorization failures, via rax:roles extensions (403), differs from the statuses returned when roles are defined directly in the validator.cfg.xml (404 and 405).\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/running-valve.html", "title": "8.6.2.0 | Recipes | Running Valve", "content": "\nValve allows Repose to run as a standalone application.\nRepose currently supports multiple ways of starting and stopping in an effort to provide the most flexibility to operators during the industry wide conversion from System V and Upstart to systemd.\nThe SystemV and Upstart mechanisms are currently deprecated, and in the future, only support for the systemd way will be provided by the standard installation.\n\nThis is the recommended way of starting/stopping Repose.\nBy default, Repose will log to both the systemd logging system via standard out/err as well as system logs in /var/log/repose.\nThis behavior can be modified by updating the log4j2.xml in the Repose configuration directory to only log to one or the other depending on the need.\n\nThis is the old way of starting/stopping Repose.\n\nAlternatively, you could start/stop Repose using the init.d script directly.\n\nAs a Java application, Repose can also be run directly from a JAR file.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/tomcat-setup.html", "title": "8.6.2.0 | Recipes | Tomcat Setup", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\nThis page describes how to run the Repose WAR in a Tomcat container.\n\nMake sure to install the Repose WAR first!\n\nThe easiest way to deploy the WAR to Tomcat is to copy it to Tomcat\u2019s deployment directory.\n\nRepose needs two parameters set in order to start with an optional third parameter to set the location of the config directory.\n\nAlternatively, the web.xml file within the war itself can be modified to include the following:\n\nYou may want to increase the size of the maximum allowed HTTP header size and number of allowed headers.\nSee Tomcat\u2019s HTTP Connector documentation for more details.\n\nRepose can use internal dispatch (within the Tomcat container) to access your deployed WARs.\n\nFor example, if you had sample.war deployed, you could set the configured root-path to /sample and then access it as if it was on the root path (e.g. curl localhost:8080 would point to localhost:8080/sample/).\n\nYou can use curl or HTTPie to send a request to Tomcat.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/user-access-events.html", "title": "8.6.2.0 | Recipes | User Access Events", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/vagrant.html", "title": "8.6.2.0 | Recipes | Vagrant", "content": "\nIf you need a quick Linux environment setup to test or evaluate Repose, Vagrant makes it easy to create a new virtual machine with the Linux distribution of your choice installed.\n\nVagrant needs a virtual machine provider such as VirtualBox.\nVirtualBox can be installed on a variety of operating systems.\nCheck out the VirtualBox Downloads page and install the binary for your operating system.\n\nCheck out the Vagrant Downloads page and install the package for your operating system.\n\nIt is extremely useful to install the Vagrant plugin for the VirtualBox Guest Additions.\nTo do so, run:\n\nFrom here you can either install a few more tools and use the automated build environment that the Repose team uses to verify a release, or you can manually set up your environment.\n\nCheck out the Git Downloads page and install the package for your operating system.\n\nTo start the Vagrant sandbox using the build environment, you will need to clone the repository and then run execute build task with the desired properties.\nOnce the sandbox is running, the environment can be accessed directly by running the vagrant ssh command from the directory containing the Vagrantfile.\n\nTo access the Repose instance from the guest, simply send a request to the configured port of 8080.\n\nThe Vagrant guest VM\u2019s also attempt to expose ports for both the Repose instance and Java Debug Wire Protocol (JDWP).\nFor Debian/Apt VM\u2019s these are 18088 & 18038 respectively and for RHEL/RPM VM\u2019s 18089 & 18039.\nTo access the Repose instance from the host simply send a request to the exposed port.\nSimilarly, to debug the Repose instance, connect a remote debugger to the JDWP port.\n\nNow you\u2019re ready to use Vagrant to create a new virtual machine instance with a Linux distro installed.\nRepose has been tested on Ubuntu and CentOS.\nSetup instructions are provided for both.\nFor additional information on Vagrant commands, check out the Vagrant Docs for the Command-Line Interface.\n\nWhen you\u2019re done with your virtual machine instance, use these instructions to clean up your resources.\n\nIf you want to save any config files you created or the Repose logs, you can copy them to the /vagrant directory which for most instances is a shared mount between the Guest VM and Host OS where the Vagrantfile is located.\nIn the manual example above, it would be the repose-vm directory.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/valve-installation.html", "title": "8.6.2.0 | Recipes | Valve Installation", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\nCovers the typical Repose setup\u2009\u2014\u2009a Valve installation (i.e., standalone application) running as a Linux service.\n\nFor instructions on starting Repose after setup, see: Running Valve.\n\nFor more information about the packages themselves, see: Packages.\n\nNative packages are not yet provided for all operating systems.\n\nTo install Repose Valve on systems that do not support Repose packages, see: Manual\n\nThis installation method is not recommended unless necessary.\nThis method does not verify or modify the environment to accommodate Repose.\n\nIf you want to manually download the application archives, they are available in our Nexus Repository.\nThe primary archives are:\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/war-installation.html", "title": "8.6.2.0 | Recipes | WAR Installation", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\nCovers setting up Repose inside of a user-provided servlet container.\n\nFor information on setting up a container after installation, see: Tomcat Setup or GlassFish Setup.\n\nFor more information about the packages themselves, see: Packages.\n\nNative packages are not yet provided for all operating systems.\n\nTo install the Repose WAR on systems that do not support Repose packages, see: Manual\n\nThis installation method is not recommended unless necessary.\nThis method does not verify or modify the environment to accommodate Repose.\n\nIf you want to manually download the application archives, they are available in our Nexus Repository.\nThe primary archives are:\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/recipes/xsd-versioning.html", "title": "8.6.2.0 | Recipes | XSD Versioning Guidelines", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/services/atom-feed-consumption.html", "title": "8.6.2.0 | Services | Atom Feed Consumption Service", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/services/datastores.html", "title": "8.6.2.0 | Services | Datastores", "content": "\nRepose uses one of the following datastore implementations to store various types of data:\n\nThe local datastore is enabled by default.\nThe others are enabled by including the appropriate service into your system model configuration.\n\nIf no other datastores are configured, then Repose will use the local datastore.\nThe local datastore will store data using the cache on each node.\nData will not be shared among the nodes, so each Repose node will have its own copy of the data.\nFor example, if using rate limiting with the local datastore, then each node will track its own limit information and limit updates will not be shared with other nodes.\n\nA Repose cluster may, at times, need to share information between cluster nodes.\nThe Distributed Datastore component allows Repose to host a simple hash-ring object store that shares consistency between all of the participating cluster nodes.\nThis, in turn, allows other hosted components as well as external programs to use the Repose cluster as a whole to store information.\nInstead of cache operations communicating through the Repose Service port (which is the port a Repose instance services requests to pass to the Origin Service), the Distributed Datastore Service will communicate through configured port(s) within the distributed datastore configuration.\nIf the Distributed Datastore Service is unable to communicate with the service on other nodes, it will fall back on the local datastore temporarily.\nOnce other nodes become reachable, the Distributed Datastore Service will return to being distributed.\n\nThe Distributed Datastore service can be added to a Repose deployment by adding it as a service (dist-datastore) within the services list of the system-model.cfg.xml file.\nAdding the Distributed Datastore Service to a Repose deployment requires that listening ports be configured within the dist-datastore.cfg.xml file.\nThe <port> element is the port configuration for the Distributed Datastore.\nWhen you configure Repose to start with the Distributed Datastore, the running Repose instance will try to find the <port> configuration that matches it\u2019s own cluster and node.\nIf only the cluster attribute is defined, the running Repose instance will assume that is the port in which to open a listener for the Distributed Datastore.\n\nThe following is a basic sample configuration.\n\nThe distributed datastore provides the option to encrypt communication between nodes using HTTP over SSL/TLS.\nAs mentioned above, this is achieved by configuring a keystore in the dist-datastore.cfg.xml file.\nThis feature can additionally provide client authentication during the SSL handshake.\nBy both validating the client credentials and encrypting communication with the client, data in the datastore is made more secure.\n\nAssuming all Repose nodes are configured identically, the most straight-forward way to make use of this security would be to use a single unique keystore as both the keystore and the truststore.\nThis can be achieved by not explicitly configuring a separate truststore.\nSince each datastore node will have a copy of the keystore, each node will trust every other node.\n\nClient authentication in SSL/TLS can act as as alternate form of client validation, performing a task similar to that of an access control list.\nAs such, the usage of client authentication may replace the need to configure the allowed-hosts section of the dist-datastore.cfg.xml file.\n\nThe that distributed datastore will use a connection pool to communicate across nodes.\nIf a connection pool is not configured, the default will be used.\nIn nearly all cases, the connection pool being used should not be the default, but rather, a connection pool should be configured to use a keystore/truststore matching the keystore/trustore configured in the distributed datastore.\nThat is, the distributed datastore may be thought of as a server, and clients in the connection pool as clients.\nBoth the client and server need to be aware of how to communicate, and so they both must be configured with the appropriate secrets.\n\nFor managing keystores and truststores, the aptly named keytool can be used.\n\nFor more details, see:\n\nThe distributed datastore shares key-space with all of the enabled cluster nodes.\nKey-space is determined by the maximum value of the distributed datastore\u2019s hashing algorithm.\nCurrently the only supported hashing algorithm is MD5.\n\nAddressing a key is done by first normalizing all of the participating cluster nodes.\nThis is done by an ascending sort.\nAfter the participating nodes have had their order normalized, the key-space is sliced up by dividing the maximum possible number of addresses by the total number of participating nodes.\nThe given key is then reduced to its numeric representation and a cluster node is looked up by performing a modulus such that (<key-value> % <number-of-cluster-members>).\n\nBy default, the internal Repose client implementation for the distributed datastore will obscure key-space by storing only the MD5 hash value of a given key and not the key\u2019s actual value.\nThis is important to note since external gets against the distributed datastore must be aware of this functionality.\nThe MD5 hash is represented as a 128bit UUID.\n\nExample Key Addressing\n\nIf an external application makes a request for data stored by Repose components, it must first hash the key using MD5 before sending the request such that\u2026\u200b\n\nGET /powerapi/dist-datastore/objects/object-key\n\nbecomes\n\nGET /powerapi/dist-datastore/objects/cecda330-5a61-26cd-1a71-d5fe34a8e302\n\nObscuring key-space is not a function of the distributed datastore service.\nThis functionality is only present in the internally consumed java cache client.\nIf an external application puts an object into the distributed datastore, the object will be stored under the value of the key given.\n\nThe repose distributed datastore component is a service that hosts a simple RESTful API that can be contacted to perform remote object store operations.\nThese operations are defined below.\n\nGET /powerapi/dist-datastore/objects/<object-key> HTTP/1.1\n\nGets a stored object from the datastore by its key.\n\nPUT /powerapi/dist-datastore/objects/<object-key> HTTP/1.1\n\nPuts an object into the datastore by its key.\n\nDELETE /powerapi/dist-datastore/objects/<object-key> HTTP/1.1\n\nDeletes an object from the datastore by its key.\n\nPATCH /powerapi/dist-datastore/objects/<object-key> HTTP/1.1\n\nPatches an object in the datastore by its key.\nIf the object does not exist, then a new one created.\nReturn the modified/new object.\nThe object must be Patchable.\n\nIn the event that a node with in a datastore cluster falls off line or is unable to respond to requests, it is removed from the node\u2019s cluster membership for a period of time.\nDuring this time, the online node will then re-address its key-space in order to continue operation.\nAfter certain periods of rest, the node may attempt to introduce the damaged cluster member into its cluster membership.\nA damaged cluster member must go through several validation passes where the member is introduced back into the addressing algorithm before it can be considered online.\nIn order to keep healthy nodes from attempting to route requests to the damaged node, a participating node may tell it\u2019s destination that the destination may not route the request and must handle the value locally.\n\nThe Repose node will open sockets each time it has to communicate with other Repose nodes to share information.\nDuring times of load this can affect performance and data integrity as when one node cannot communicate with another it will mark that node damaged and store/create information locally.\nOne way this can happen is if the user running repose hits their open file limit.\nLuckily this can be mitigated by increasing the open file limit for the user running Repose.\n\nCurrently Repose instances do not report Distributed Datastore information to JMX.\nThis is something that has been done in the past, but an upgrade to the metrics library used has made this capability incompatible with the current codebase.\n\nAt times, Repose instances may need to share information between nodes that are unaware of each other.\nAn example of this is a dynamic containerized environment like OpenShift or other 12-Factor environment.\n\nThe Remote Datastore Service allows dynamic isolated Repose instances to use a single static Repose instance\u2019s object store.\nThe Remote Datastore Service communicates to the configured host through the configured port.\nIf the Remote Datastore Service is unable to communicate with the configured object store, it will fall back on the local datastore temporarily.\nThe Remote Datastore Service will return to using the configured object store as soon as it becomes reachable again.\n\nThe static Repose instance is simply configured as a single node cluster with the distributed datastore service enabled.\nThis distributed datastore is typically configured with both a keystore so that HTTPS is used and a truststore so that all clients must properly authenticate before the session is established.\nThen all of the dynamic clients are configured with a remote datastore and the same keystore to authenticate with and the same truststore to confirm the HTTPS session.\n\nThe following is a basic sample configuration.\n\nRefer to the http-connection-pool.cfg.xml documentation for setting up Client Authentication on the connection pool used to connect to the Remote Datastore.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/services/health-check.html", "title": "8.6.2.0 | Services | Health Check service", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/services/http-connection-pool.html", "title": "8.6.2.0 | Services | HTTP Connection Pool service", "content": "\nThe HTTP Connection Pool Service allows a centralized way of managing and reusing http connections for outbound communication.\n\nThe connection pool service uses the concept of named pools.\nA named pool has a number of configuration options on it that describe how a connection from that pool should behave.\nConnections from a pool are reused to cut down on the overhead of connection negotiation when resources are frequently accessed.\nThe id/name of the pool corresponds to the connection pool id found in other service\u2019s and filter\u2019s configurations, indicating that outbound connections from that component should use the matching pool.\n\nIf the origin service doesn\u2019t support chunked encoding, it can be turned off easily.\nAdd or update the chunked-encoding attribute for your default pool to false.\n\nThis can be done for any other pool as well, if it\u2019s known that it will be used to communicate to a service that doesn\u2019t support chunked encoding.\n\nIf the connection pool is filling up, but more resources are available on the machine Repose is running on, the pool can be expanded to allow more concurrent connections.\nThis is most useful if wait times are high or requests are timing out.\nThe size of the pools can be increased by raising http.conn-manager.max-total and http.conn-manager.max-per-route.\n\nSome services require a static header be present just for the purposes of identification; this can easily be done by adding the headers element to the pool configuration.\n\nSee SSL/TLS Client Authentication\n\nFor more information about the http.* attributes or the underlying connection pool see Apache Connection Management.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/services/metrics.html", "title": "8.6.2.0 | Services | Metrics Service", "content": "\nThe Metrics Service enables the registration, collection, and reporting of metrics across Repose.\n\nMetrics collected by this service provide insight into the state of Repose and its components at any given time.\n\nThe goal of the Metrics Service is to provide a simple, convenient mechanism for gathering and reporting metrics.\nTo that end, the Metrics Service manages a centralized metrics registry and reporters for that registry.\nBy exposing the Metrics Service as a Java @Named component, other Repose components may easily leverage the ability to record metrics.\n\nImplementation wise, the Metrics Service is a light-weight wrapper around the Dropwizard metrics library.\nThis allows the service to offer all of the capabilities of a powerful, open-source metrics library.\n\nFor more information about what the Metrics service can do, see the Dropwizard Metrics User Manual.\n\nAll metrics reported to this service will be reported to JMX.\n\nIn order to report metrics to JMX, this service must translate metric names into JMX ObjectNames.\nA metric can be named virtually anything, but names often follow the <segment1>.<segment2>.<\u2026\u200b>.<segmentn> convention.\nA simplified general form for an object name is <domain>:<key1>=<value1>,<key2>=<value2>,<\u2026\u200b>,<keyn>=<valuen>.\nTo go from metric name to object name, the translation process will start by prepending the metric name with the hostname of the host running Repose.\nNext, it will split the metric name using . as a delimiter.\nThe index of each delimited segment will act as the key for that segment, and the value of the segment will act as the value.\n\nFor example, a metric named org.openrepose.example.count will be reported to JMX as <hostname>:001=\"org\",002=\"openrepose\",003=\"example\",004=\"count\".\n\nWhile this approach can cause some difficulty in querying metrics from JMX, it provides easier navigation of metrics when using a tool such as JConsole.\n\nThis service supports the automatic aggregation of certain metrics.\nIn some cases, aggregating metrics provides useful insight into the system at a level where individual metrics may not be present.\nFor example, a Meter on its own might track the status codes sent in responses from a single filter.\nHowever, we want to be able to view the status codes send in responses from all filters.\nFor that purpose, this service supplies a SummingMeter.\nSee [SummingMeter] for more details.\n\nThe following nested sections provide details about the supported aggregation metrics.\n\nMultiMeter s can be used to mark multiple Meter s at the same time.\nWhile this makes MultiMeter s generally useful, when used in conjunction with the SummingMeterFactory, they are used to track an additional Meter which serves as the sum of all Meter s created by the SummingMeterFactory.\n\nA summing Meter should be constructed by utilizing the SummingMeterFactory accessible via this service.\n\nThe SummingMeterFactory also provides support for Meter trees.\nThese trees enable nesting of Meter s in more interesting ways.\n\nThe following lists attempt to aggregate all of the metrics being reported to this service by various components.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/services/phone-home.html", "title": "8.6.2.0 | Services | Phone Home Service", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/services/response-messaging.html", "title": "8.6.2.0 | Services | Response Messaging service", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/welcome/faq.html", "title": "8.6.2.0 | Welcome to Repose | FAQ", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\nThese are frequently asked questions.  If you don\u2019t find an answer to your question here, check out the Contact Us page for information on getting in touch with the team.\n\nPlease read our Troubleshooting page.\n\nIN PROGRESS\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/welcome/release-notes.html", "title": "8.6.2.0 | Welcome to Repose | Release Notes", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\nAs part of the upgrade, some metric names reported by various components have been changed.\nFurthermore, all metrics reported to JMX via the Metrics Service now follow a new naming scheme.\nDue to a technical issue with the new version of the metric library, EHCache metrics are no longer being reported, but there is planned work to restore them.\nSee Metrics Service for details on the metrics currently being reported.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/welcome/style-guide.html", "title": "8.6.2.0 | Welcome to Repose | Style Guide", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\nDon\u2019t wrap text at a fixed column width.\nInstead, put each sentence on its own line, a technique called sentence per line.\nThis technique is similar to how you write and organize source code.\nThe result can be spectacular.\n\nHere are some of the advantages of using the sentence per line style:\n\nWe picked up this idea from the writing guide in the Neo4j documentation.\nHowever, it seems like the idea dates back a discovery by Buckminster Fuller in the 1930s, who called it ventilated prose.\nThe technique was also recommended in 2009 by Brandon Rhodes in a blog post about Semantic Linefeeds.\n\nIt\u2019s important to note that this technique works because AsciiDoc doesn\u2019t treat wrapped lines in prose as hard line breaks.\nAt least, it doesn\u2019t show up that way to the reader.\nThe line breaks between contiguous lines of prose will not be visible in the rendered document (i.e., as the reader sees it).\n\nWhile line breaks don\u2019t appear in the output, a blank line introduces a new paragraph. Use paragraphs to structure your text and don\u2019t make them too large.\n\nSection titles should be defined using Atx-style.\n\nIn the Atx-style, the section title is defined on a single line.\nThe section title begins with one or more equal characters (i.e., =) followed by a space and the section title.\nThe number of leading characters representing the depth.\nThe top-level section is reserved for the document title, so the first section in the document will have two leading characters.\n\nOf the supported section title styles, this style requires the least number of characters, and it\u2019s intuitive since the number of leading characters represents the heading level.\n\nUse * to define lists rather than -.\nNesting in lists will correspond to the number of leading asterisks.\n", "site_name": "http://openrepose.org/versions/"}, {"topic_url": "8.6.2.0/welcome/troubleshooting.html", "title": "8.6.2.0 | Welcome to Repose | Troubleshooting", "content": "\nThis version of the docs is a work in progress.\nIf you don\u2019t see what you are looking for check the legacy wiki.\n\nThis page summarizes the different methods which can be used to get more information on the state of Repose and how it interacts with the clients, origin service, and third party services.\nMost of these methods can be used in a production deployment.\n\nThis should be used in a controlled environment (i.e. not production) and should not be used for more than a few minutes at a time due to the amount of logging that occurs.\n\nIntrafilter Logging allows you to see the modified output of each filter as the request goes through the filter chain which makes debugging configurations easier.\nThis setting adds a UUID header to the request and another to the response.\n\nWhen the logger is set to TRACE, you will see the following information:\n\nThe TRACE setting is the most verbose logging setting.\n\nTo enable intrafilter logging, the corresponding named log4j2 logger should be set to the TRACE level.\nThis can be achieved by adding a line like the following to the log4j2.xml file in your Repose configuration directory.\n\nThis is an example of the log line that you will see for the request and for the response.\nThese lines are formatted for convenience.\nThe log line will be a single line without carriage returns.\n\nRepose can report on which filters handled the client request and how long each filter took.\nThis allows you to verify that all expected filters handled the request.\n\nTo enable this, add the following header to the client request:\nx-trace-request: true\n\nThe Repose response to the client will contain the following header added to the response, one for each filter which handled the request:\nx-[filter name]: [time]ms\n\nThe x-trace-request header can be easily added to a test request using curl and the -H [header] flag.\nFor example:\n\nThe following example contains three headers which Repose added to the response.\nThese headers indicate that the the client-auth, http-logging, and default-router all handled the request, taking 0, 6, and 0 ms respectively.\n\nYou can view all of the data being sent and received to the origin service and other third party APIs (e.g. Identity) by turning on Apache HttpClient logging.\n\nIn log4j2.xml, update the org.apache logger to the debug level. For example:\n\nRepose instruments its internal operations, such as the types of response codes returned from Repose or the origin service and the number of active requests.\nThis information is published through JMX and can be accessed through any JMX client.\nJConsole is a popular choice to access information published through JMX as it is shipped with the JDK.\n\nIN PROGRESS\n", "site_name": "http://openrepose.org/versions/"}]